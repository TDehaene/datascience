{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron project data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "enron_data = pickle.load(open(r\"C:\\Users\\dehaeth\\Documents\\Tools\\Python\\Oefeningen\\Udacity\\Machine learning intor\\ud120-projects-master\\final_project\\final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salary': 1111258, 'to_messages': 3627, 'deferral_payments': 'NaN', 'total_payments': 8682716, 'exercised_stock_options': 19250000, 'bonus': 5600000, 'restricted_stock': 6843672, 'shared_receipt_with_poi': 2042, 'restricted_stock_deferred': 'NaN', 'total_stock_value': 26093672, 'expenses': 29336, 'loan_advances': 'NaN', 'from_messages': 108, 'other': 22122, 'from_this_person_to_poi': 30, 'poi': True, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 1920000, 'email_address': 'jeff.skilling@enron.com', 'from_poi_to_this_person': 88}\n"
     ]
    }
   ],
   "source": [
    "print enron_data[\"SKILLING JEFFREY K\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of people, features and poi's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of people: 146\n",
      "number of features: 21\n",
      "number of poi's: 18\n"
     ]
    }
   ],
   "source": [
    "print \"number of people: \" + str(len(enron_data))\n",
    "print \"number of features: \" + str(len(enron_data.values()[0]))\n",
    "poi = 0\n",
    "for person in enron_data.keys():\n",
    "    if enron_data[person]['poi'] == True:\n",
    "        poi +=1\n",
    "        \n",
    "print \"number of poi's: \" + str(poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of real poi's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real pois: 35\n"
     ]
    }
   ],
   "source": [
    "poi_file = 0\n",
    "poi_file_emails = 0\n",
    "\n",
    "with open(r'C:\\Users\\dehaeth\\Documents\\Tools\\Python\\Oefeningen\\Udacity\\Machine learning intor\\ud120-projects-master\\final_project\\poi_names.txt','r') as enronnamefile:\n",
    "    for line in enronnamefile.readlines():\n",
    "        if '(y)' in line:\n",
    "            poi_file_emails += 1\n",
    "            poi_file += 1\n",
    "        elif '(n)' in line:\n",
    "            poi_file += 1\n",
    "              \n",
    "            \n",
    "print 'real pois: ' + str(poi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock value of an individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095040\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print enron_data['PRENTICE JAMES']['total_stock_value']\n",
    "print enron_data['COLWELL WESLEY']['from_this_person_to_poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who took the largest cake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jeffrey skilling: 8682716\n",
      "ken lay: 103559793\n",
      "andrew fastow: 2424083\n"
     ]
    }
   ],
   "source": [
    "print \"jeffrey skilling: \" + str(enron_data['SKILLING JEFFREY K']['total_payments'])\n",
    "print \"ken lay: \" + str(enron_data['LAY KENNETH L']['total_payments'])\n",
    "print \"andrew fastow: \" + str(enron_data['FASTOW ANDREW S']['total_payments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking salaries and email addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "quantified_email = 0\n",
    "quantified_salary = 0\n",
    "\n",
    "for person in enron_data.keys():\n",
    "    if enron_data[person]['salary'] != 'NaN':\n",
    "        quantified_salary+=1\n",
    "    if enron_data[person]['email_address'] != 'NaN':\n",
    "        quantified_email+=1    \n",
    "        \n",
    "print quantified_email\n",
    "print quantified_salary     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing financial info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "14.3835616438\n",
      "31\n",
      "19.8717948718\n"
     ]
    }
   ],
   "source": [
    "missing_payment = 0\n",
    "\n",
    "for person in enron_data.keys():\n",
    "    if enron_data[person]['total_payments'] == 'NaN':\n",
    "        missing_payment+=1   \n",
    "        \n",
    "print missing_payment\n",
    "print float(missing_payment) / float(len(enron_data.keys())) * 100\n",
    "print missing_payment + 10\n",
    "print float(missing_payment + 10) / float(len(enron_data.keys()) + 10) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing financial info POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "10\n",
      "35.7142857143\n"
     ]
    }
   ],
   "source": [
    "missing_payment = 0\n",
    "poi = 0\n",
    "\n",
    "for person in enron_data.keys():\n",
    "    if enron_data[person]['poi'] == True:\n",
    "        poi += 1\n",
    "        if enron_data[person]['total_payments'] == 'NaN':\n",
    "            missing_payment+=1   \n",
    "        \n",
    "        \n",
    "print missing_payment\n",
    "print float(missing_payment) / float(poi) * 100\n",
    "print missing_payment + 10\n",
    "print (float(missing_payment + 10) / float(poi + 10)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
