{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import csv\n",
    "import pandas as pd\n",
    "import utils\n",
    "import re\n",
    "import decimal\n",
    "import optparse\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseNumbers( s):\n",
    "        \"\"\"\n",
    "        Parses a string that represents a number into a decimal data type so that\n",
    "        we can match the quantity field in the db with the quantity that appears\n",
    "        in the display name. Rounds the result to 2 places.\n",
    "        \"\"\"\n",
    "        ss = utils.unclump(s)\n",
    "\n",
    "        m3 = re.match('^\\d+$', ss)\n",
    "        if m3 is not None:\n",
    "            return decimal.Decimal(round(float(ss), 2))\n",
    "\n",
    "        m1 = re.match(r'(\\d+)\\s+(\\d)/(\\d)', ss)\n",
    "        if m1 is not None:\n",
    "            num = int(m1.group(1)) + (float(m1.group(2)) / float(m1.group(3)))\n",
    "            return decimal.Decimal(str(round(num,2)))\n",
    "\n",
    "        m2 = re.match(r'^(\\d)/(\\d)$', ss)\n",
    "        if m2 is not None:\n",
    "            num = float(m2.group(1)) / float(m2.group(2))\n",
    "            return decimal.Decimal(str(round(num,2)))\n",
    "\n",
    "        return None\n",
    "    \n",
    "    \n",
    "\n",
    "def matchUp( token, ingredientRow):\n",
    "        \"\"\"\n",
    "        Returns our best guess of the match between the tags and the\n",
    "        words from the display text.\n",
    "        This problem is difficult for the following reasons:\n",
    "            * not all the words in the display name have associated tags\n",
    "            * the quantity field is stored as a number, but it appears\n",
    "              as a string in the display name\n",
    "            * the comment is often a compilation of different comments in\n",
    "              the display name\n",
    "        \"\"\"\n",
    "        ret = []\n",
    "\n",
    "        # strip parens from the token, since they often appear in the\n",
    "        # display_name, but are removed from the comment.\n",
    "        token = utils.normalizeToken(token)\n",
    "        decimalToken = parseNumbers(token)\n",
    "\n",
    "        for key, val in ingredientRow.iteritems():\n",
    "            if isinstance(val, str):\n",
    "\n",
    "                for n, vt in enumerate(utils.tokenize(val)):\n",
    "                    if utils.normalizeToken(vt) == token:\n",
    "                        ret.append(key.upper())\n",
    "\n",
    "            elif decimalToken is not None:\n",
    "                try:\n",
    "                    if val == decimalToken:\n",
    "                        ret.append(key.upper())\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "    \n",
    "def addPrefixes( data):\n",
    "        \"\"\"\n",
    "        We use BIO tagging/chunking to differentiate between tags\n",
    "        at the start of a tag sequence and those in the middle. This\n",
    "        is a common technique in entity recognition.\n",
    "        Reference: http://www.kdd.cis.ksu.edu/Courses/Spring-2013/CIS798/Handouts/04-ramshaw95text.pdf\n",
    "        \"\"\"\n",
    "        prevTags = None\n",
    "        newData = []\n",
    "\n",
    "        for n, (token, tags) in enumerate(data):\n",
    "\n",
    "            newTags = []\n",
    "\n",
    "            for t in tags:\n",
    "                p = \"B\" if ((prevTags is None) or (t not in prevTags)) else \"I\"\n",
    "                newTags.append(\"%s-%s\" % (p, t))\n",
    "\n",
    "            newData.append((token, newTags))\n",
    "            prevTags = tags\n",
    "\n",
    "        return newData\n",
    "\n",
    "\n",
    "def bestTag( tags):\n",
    "\n",
    "        if len(tags) == 1:\n",
    "            return tags[0]\n",
    "\n",
    "        # if there are multiple tags, pick the first which isn't COMMENT\n",
    "        else:\n",
    "            for t in tags:\n",
    "                if (t != \"B-COMMENT\") and (t != \"I-COMMENT\"):\n",
    "                    return t\n",
    "\n",
    "        # we have no idea what to guess\n",
    "        return \"OTHER\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the NER system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the dataset\n",
    "And parse it to a format which we the trainer can read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "csv_path = 'nyt-ingredients-snapshot-2015.csv'\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "df_slice = df.iloc[:]\n",
    "\n",
    "with open(r\"training_file\",'w',encoding='utf8') as file:\n",
    "    for index, row in df_slice.iterrows():\n",
    "        try:\n",
    "            # extract the display name\n",
    "            display_input = utils.cleanUnicodeFractions(row[\"input\"])\n",
    "            tokens = list(utils.tokenize(display_input))\n",
    "            del(row[\"input\"])\n",
    "\n",
    "            rowData = addPrefixes([(t, matchUp(t, row)) for t in tokens])\n",
    "\n",
    "            for i, (token, tags) in enumerate(rowData):\n",
    "                features = utils.getFeatures(token, i+1, tokens)\n",
    "                file.write(str( utils.joinLine([token] + features + [bestTag(tags)])) + '\\n')\n",
    "\n",
    "        # ToDo: deal with this\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_lines[432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
