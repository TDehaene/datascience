{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delacre combinations of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import pprint\n",
    "import treetaggerwrapper\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Stanford POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger as POS_Tag\n",
    "\n",
    "homepath = r'C:\\Users\\peter\\Documents\\Tools\\stanford-postagger-full-2017-06-09'\n",
    "taggerpath = os.path.join(homepath,r'models\\french.tagger')\n",
    "jarpath = os.path.join(homepath,'stanford-postagger.jar')\n",
    "\n",
    "st = POS_Tag(taggerpath,jarpath)\n",
    "\n",
    "def extract_tokens_noun_adj(text):\n",
    "    # tokenize and tag using Stanford POS tagger:\n",
    "    tokenized_text = nltk.tokenize.word_tokenize(txt)\n",
    "    tagged_text = st.tag(tokenized_text)\n",
    "    tokens_stanford_noun = [tag[0].lower() for tag in tagged_text if (tag[1][0] == 'N' )]\n",
    "    tokens_stanford_adj = [tag[0].lower() for tag in tagged_text if ( tag[1] == 'ADJ')]\n",
    "    \n",
    "    return tokens_stanford_noun,tokens_stanford_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V\t\t\tV\t\tindicative verb\n",
    "\n",
    "VS\t\t\tV\t\tsubjonctive verb\n",
    "\n",
    "VINF\t\tV\t\tinfinitival verb\n",
    "\n",
    "VPP\t\t\tV\t\tpast participle\n",
    "\n",
    "VPR\t\t\tV\t\tpresent participle\n",
    "\n",
    "VIMP\t\tV\t\timperative verb\n",
    "\n",
    "NC\t\t\tN\t\tcommon noun\n",
    "\n",
    "NPP\t\t\tN\t\tpropoer noun\n",
    "\n",
    "CS\t\t\tC\t\tcoordinating conjunction\n",
    "\n",
    "CC\t\t\tC\t\tsubordinating conjunction (complementizer)\n",
    "\n",
    "CLS\t\t\tCL\t\tnominative clitic\n",
    "\n",
    "CLO\t\t\tCL\t\taccusative or dative clitic\n",
    "\n",
    "CLR\t\t\tCL\t\treflexive clitic (whether its interpretation is truly reflexive or not)\n",
    "\n",
    "P\t\t\tP\t\tnon amalgamated preposition\n",
    "\n",
    "P+D\t\t\tP+D\t\tprep+determiner amalgam\n",
    "\n",
    "P+PRO\t\tP+PRO\tprep+relative pronoun amalgam (auquel (to which))\n",
    "\n",
    "I\t\t\tI\t\tinterjection\n",
    "\n",
    "PONCT\t\tPONCT\t\tpunctuation\n",
    "\n",
    "ET\t\t\tET\t\tforeign words, with a POS that is not guessable from context\n",
    "\n",
    "ADJ\t\t\tA\t\tnon interrogative adjectives\n",
    "\n",
    "ADJWH\t\tA\t\tinterrogative adjectives\n",
    "\n",
    "ADV\t\t\tADV\t\tnon interrogative adjectives\n",
    "\n",
    "ADVWH\t\tADV\t\tinterrogative adjectives\n",
    "\n",
    "PRO\t\t\tPRO\t\tneither relative nor interrogative pronouns\n",
    "\n",
    "PROREL\t\tPRO\t\trelative pronouns\n",
    "\n",
    "PROWH\t\tPRO\t\tinterrogative pronouns\n",
    "\n",
    "DET\t\t\tD\t\tnon interrogative nor relative determiners\n",
    "\n",
    "DETWH\t\tD\t\tinterrogative or relative determiners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure TreeTagger\n",
    "which supposedly both tags and lemmatizes your text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "lemma_docs= []\n",
    "\n",
    "java_path = r\"C:\\Program Files (x86)\\Java\\jre1.8.0_144\\bin\\java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "def extract_lemma_noun_adj(txt):\n",
    "    try:\n",
    "        tags = treetaggerwrapper.make_tags(tagger.tag_text(txt))\n",
    "        \n",
    "        lemmas_noun = [tag.lemma.lower() for tag in tags if (type(tag) == treetaggerwrapper.Tag) and (tag.pos == 'NOM')]\n",
    "        lemmas_adj = [tag.lemma.lower() for tag in tags if (type(tag) == treetaggerwrapper.Tag) and (tag.pos =='ADJ')]\n",
    "        \n",
    "        return lemmas_noun,lemmas_adj\n",
    "    except:\n",
    "        print(\"error\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_metric(application,applications):\n",
    "    \n",
    "    # calc P(ingr)\n",
    "    \n",
    "    flat_list = [item for sublist in applications for item in sublist]\n",
    "    cnt_freqdist = collections.Counter(flat_list)\n",
    "    \n",
    "    metrics = []\n",
    "    \n",
    "    # calc P(ingr|application)\n",
    "    \n",
    "    application_freqdist = collections.Counter(application)\n",
    "        \n",
    "    for ingredient in application_freqdist.keys():\n",
    "            \n",
    "        p_ingr_app = (application_freqdist[ingredient] / len(application))\n",
    "        p_ingr = (cnt_freqdist[ingredient] / len(flat_list))\n",
    "            \n",
    "        metric = p_ingr_app * ((p_ingr_app - p_ingr) / (1 - p_ingr))\n",
    "        \n",
    "        metrics.append([ingredient,metric])\n",
    "        \n",
    "    headers = [\"ingredient\",'score']\n",
    "    df = pd.DataFrame(metrics, columns=headers).sort_values(by = 'score',ascending = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ingredient classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "any_in = lambda a, b: any(i in b for i in a)    \n",
    "        \n",
    "def find_food(candidate,language):\n",
    "    full_hierarchy_list = []\n",
    "    \n",
    "    # core idea: find the full lexicology path for any synonym of the word.\n",
    "    # if somewhere in the upward path, the candidate arrives at a node 'food', 'plant' or 'ingredient':\n",
    "    # then we have a fairly certain match for a true ingredient\n",
    "    \n",
    "    for synset in wn.synsets(candidate,lang=language):\n",
    "        hierarchy = wn.synset(synset.name())\n",
    "        hierarchy_list = (list(hierarchy.closure(lambda s: s.hypernyms())))\n",
    "        distill_words = [x.name().split('.')[0] for x in hierarchy_list]\n",
    "        if len(full_hierarchy_list) == 0:\n",
    "            full_hierarchy_list = distill_words\n",
    "        else:\n",
    "            full_hierarchy_list += distill_words\n",
    "    return any_in(full_hierarchy_list,['food','plant','ingredient'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ingredient     score\n",
      "2       beurre  0.008986\n",
      "1   champignon  0.007188\n",
      "7     bouillon  0.005213\n",
      "3          riz  0.003162\n",
      "4        purée  0.003162\n",
      "10         jus  0.003162\n",
      "11      citron  0.003162\n",
      "0       poulet  0.002500\n",
      "6       farine  0.002500\n",
      "12       sauce  0.001135\n",
      "8        poule  0.000782\n",
      "14      poivre  0.000782\n",
      "5         roux  0.000104\n",
      "9          eau  0.000104\n",
      "15      viande -0.000968\n",
      "13         sel -0.001722\n",
      "   ingredient     score\n",
      "6      viande  0.003308\n",
      "12        œuf  0.002698\n",
      "13      crème  0.002698\n",
      "3         eau  0.002075\n",
      "4      légume  0.002075\n",
      "8        roux  0.002075\n",
      "14   moutarde  0.001439\n",
      "18        sel  0.001320\n",
      "15   bouillon  0.000790\n",
      "0      épaule  0.000668\n",
      "16    mélange  0.000668\n",
      "7   casserole  0.000668\n",
      "11      jaune  0.000668\n",
      "1        veau  0.000352\n",
      "19     poulet  0.000031\n",
      "9      farine  0.000031\n",
      "5      oignon  0.000031\n",
      "2        cube  0.000031\n",
      "10     beurre -0.000552\n",
      "17      sauce -0.000634\n",
      "   ingredient     score\n",
      "6        pain  0.004246\n",
      "7        bœuf  0.004246\n",
      "17        sel  0.003211\n",
      "0     carotte  0.001868\n",
      "4         ail  0.001868\n",
      "8        côté  0.001868\n",
      "1       pomme  0.001868\n",
      "11    laurier  0.001868\n",
      "12       thym  0.001868\n",
      "2        cube  0.001324\n",
      "3      oignon  0.001324\n",
      "5    moutarde  0.000769\n",
      "15       plat  0.000462\n",
      "9         vin  0.000462\n",
      "16      sauce  0.000202\n",
      "10       veau  0.000188\n",
      "14     légume -0.000091\n",
      "13     viande -0.000377\n",
      "18     beurre -0.001270\n"
     ]
    }
   ],
   "source": [
    "# define datapath:\n",
    "recipe_path = r'C:\\Users\\peter\\Documents\\GitHub\\datascience\\nlp\\French NLP\\marmitton'\n",
    "\n",
    "# define ingredient of interest, with their respective application of interest\n",
    "combo_of_interest =  ['beurre','sel']\n",
    "\n",
    "# we will create a list with applications of interest: those who contain these two tags\n",
    "applications_of_interest = []\n",
    "\n",
    "for filename in os.listdir(recipe_path):\n",
    "    with open(os.path.join(recipe_path,filename),'r') as f:\n",
    "        \n",
    "        txt = f.read()\n",
    "        tokens_stanford_noun, tokens_stanford_adj = extract_tokens_noun_adj(txt)\n",
    "        lemmas_treetagger_noun, lemmas_treetagger_adj = extract_lemma_noun_adj(txt)\n",
    "\n",
    "        # for now, only keep the TreeTagger output, which seems to perform better anyway     \n",
    "        # in this step: perform filtering to only obtain foods\n",
    "        lemmas_food = [candidate for candidate in lemmas_treetagger_noun if find_food(candidate,'fra') == True]\n",
    "        \n",
    "        # if the tags of interest can be found: pass it on:\n",
    "        if all(x in lemmas_food for x in combo_of_interest):\n",
    "            applications_of_interest.append(lemmas_food)  \n",
    "        \n",
    "# for every ingredient in the application of interest: calculate the metrics, which identifies the 'most relevant' ingredients per relevant application:\n",
    "for application in applications_of_interest:\n",
    "    print(calc_metric(application,applications_of_interest))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_food('coffee','eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info: synset languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['als',\n",
       " 'arb',\n",
       " 'bul',\n",
       " 'cat',\n",
       " 'cmn',\n",
       " 'dan',\n",
       " 'ell',\n",
       " 'eng',\n",
       " 'eus',\n",
       " 'fas',\n",
       " 'fin',\n",
       " 'fra',\n",
       " 'glg',\n",
       " 'heb',\n",
       " 'hrv',\n",
       " 'ind',\n",
       " 'ita',\n",
       " 'jpn',\n",
       " 'nno',\n",
       " 'nob',\n",
       " 'pol',\n",
       " 'por',\n",
       " 'qcn',\n",
       " 'slv',\n",
       " 'spa',\n",
       " 'swe',\n",
       " 'tha',\n",
       " 'zsm']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wn.langs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Marmiton subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client['local']\n",
    "\n",
    "results = db.marmiton_local.aggregate([\n",
    "    {\"$match\": {\"ingredients.by_line\" : {\"$exists\" : True, \"$not\" : {\"$size\": 0}}}},\n",
    "    {'$project': { 'ingredients.by_line' : 1 ,'_id':0}}\n",
    "])\n",
    "\n",
    "# define ingredient of interest, with their respective application of interest\n",
    "combo_of_interest =  ['tomate','oignon']\n",
    "\n",
    "applications_of_interest = []\n",
    "\n",
    "for result in results:\n",
    "    text = \" \".join(result[\"ingredients\"]['by_line'])\n",
    "    \n",
    "    lemmas_treetagger_noun, lemmas_treetagger_adj = extract_lemma_noun_adj(text)\n",
    "\n",
    "    # for now, only keep the TreeTagger output, which seems to perform better anyway     \n",
    "    # in this step: perform filtering to only obtain foods\n",
    "    lemmas_food = [candidate for candidate in lemmas_treetagger_noun if find_food(candidate,'fra') == True]\n",
    "        \n",
    "    # if the tags of interest can be found: pass it on:\n",
    "    if all(x in lemmas_food for x in combo_of_interest):\n",
    "        applications_of_interest.append(lemmas_food)  \n",
    "        \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every ingredient in the application of interest: calculate the metrics, which identifies the 'most relevant' ingredients per relevant application:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for application in applications_of_interest:\n",
    "    metrics.append(calc_metric(application,applications_of_interest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max scaling on the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.112634919753\n",
      "-0.00211520365081\n"
     ]
    }
   ],
   "source": [
    "full_metrics = pd.concat(metrics)\n",
    "max_score = full_metrics[\"score\"].max()\n",
    "min_score = full_metrics[\"score\"].min()\n",
    "\n",
    "print(max_score)\n",
    "print(min_score)\n",
    "\n",
    "for metric in metrics:\n",
    "    metric['normalized'] = ((metric[\"score\"] - min_score) / (max_score - min_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ingredient     score  normalized\n",
      "0       coco  0.039751    0.364849\n",
      "4     poivre  0.033918    0.314014\n",
      "3        sel  0.030150    0.281180\n",
      "2     oignon  0.026449    0.248923\n",
      "1     tomate  0.024590    0.232721\n"
     ]
    }
   ],
   "source": [
    "print(metrics[599])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ingredient     score  normalized\n",
      "11     cerise  0.006819    0.077855\n",
      "4      lardon  0.006742    0.077183\n",
      "7    moutarde  0.006714    0.076939\n",
      "9       herbe  0.006502    0.075099\n",
      "1         eau  0.006439    0.074545\n",
      "8     basilic  0.006361    0.073867\n",
      "0      farine  0.006276    0.073125\n",
      "2      beurre  0.005725    0.068328\n",
      "5       olive  0.003560    0.049461\n",
      "3         sel  0.002242    0.037970\n",
      "6      oignon  0.000475    0.022570\n",
      "10     tomate -0.000413    0.014834\n"
     ]
    }
   ],
   "source": [
    "print(metrics[300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score offset\n",
    "This allows an element like coco, which appears in an application where the words of interest are very prominent, to be classified higher than for example 'cerise', which is the top in an application where the words of interest are less prominent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    tomato_value = metric.loc[metric['ingredient'] == 'tomate']['normalized'].values[0]\n",
    "    oignon_value = metric.loc[metric['ingredient'] == 'oignon']['normalized'].values[0]\n",
    "    \n",
    "    metric[\"ofset_score\"] = metric['normalized'] * (tomato_value + oignon_value) / (1 + tomato_value - oignon_value)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ingredient     score  normalized  ofset_score\n",
      "0       coco  0.039751    0.364849     0.178621\n",
      "4     poivre  0.033918    0.314014     0.153734\n",
      "3        sel  0.030150    0.281180     0.137659\n",
      "2     oignon  0.026449    0.248923     0.121867\n",
      "1     tomate  0.024590    0.232721     0.113934\n"
     ]
    }
   ],
   "source": [
    "print(metrics[599])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and sort\n",
    "to obtain the best matching ingredients with 'tomato' and 'oignon'.\n",
    "The group by is necessary since for example 'pain' appeared multiple times in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_metrics = pd.concat(metrics).groupby(['ingredient']).max().sort_values(by = 'ofset_score',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               score  normalized  ofset_score\n",
      "ingredient                                   \n",
      "oignon      0.046620    0.424704     0.324472\n",
      "chevreuil   0.039985    0.366889     0.179620\n",
      "poulpe      0.039956    0.366635     0.179495\n",
      "lentille    0.039927    0.366380     0.179371\n",
      "mayonnaise  0.039824    0.365487     0.178934\n",
      "steak       0.039795    0.365232     0.178809\n",
      "coco        0.039751    0.364849     0.178621\n",
      "lard        0.039678    0.364210     0.178308\n",
      "ciboulette  0.039649    0.363954     0.178183\n",
      "fromage     0.039310    0.361006     0.176740\n",
      "pain        0.039089    0.359077     0.175795\n",
      "sauce       0.038897    0.357401     0.174975\n",
      "pomme       0.038704    0.355720     0.174152\n",
      "carotte     0.038287    0.352087     0.172374\n",
      "œuf         0.038093    0.350394     0.171545\n",
      "piment      0.038018    0.349742     0.171225\n",
      "thym        0.037958    0.349220     0.170970\n",
      "bouquet     0.037838    0.348174     0.170458\n",
      "vin         0.037099    0.341736     0.167306\n",
      "poivron     0.070106    0.629375     0.164971\n",
      "boîte       0.069575    0.624751     0.163145\n",
      "poivre      0.042813    0.391527     0.153734\n",
      "ail         0.038870    0.357166     0.151104\n",
      "olive       0.080697    0.721676     0.149442\n",
      "tomate      0.044441    0.405717     0.146095\n",
      "sel         0.030150    0.281180     0.137659\n",
      "rôti        0.015575    0.154163     0.117780\n",
      "pin         0.032935    0.305452     0.117344\n",
      "sucre       0.032087    0.298058     0.114503\n",
      "veau        0.027064    0.254283     0.114369\n",
      "...              ...         ...          ...\n",
      "échalote    0.019722    0.190304     0.053747\n",
      "lotte       0.049003    0.445475     0.043308\n",
      "curry       0.048781    0.443538     0.043120\n",
      "citron      0.047966    0.436440     0.042430\n",
      "pruneau     0.020397    0.196184     0.039612\n",
      "oseille     0.020386    0.196087     0.039592\n",
      "vermicelle  0.020375    0.195989     0.039573\n",
      "fleur       0.020363    0.195892     0.039553\n",
      "emmental    0.020347    0.195746     0.039523\n",
      "cardamome   0.020341    0.195697     0.039514\n",
      "morue       0.020285    0.195209     0.039415\n",
      "pizza       0.020274    0.195111     0.039395\n",
      "yaourt      0.020263    0.195013     0.039376\n",
      "laitue      0.020263    0.195013     0.039376\n",
      "épinard     0.020263    0.195013     0.039376\n",
      "tournesol   0.020251    0.194916     0.039356\n",
      "chou        0.020251    0.194916     0.039356\n",
      "tasse       0.020240    0.194818     0.039336\n",
      "saumon      0.020240    0.194818     0.039336\n",
      "lasagne     0.020229    0.194720     0.039316\n",
      "calamar     0.020195    0.194427     0.039257\n",
      "mozzarella  0.020184    0.194329     0.039237\n",
      "fenouil     0.032786    0.304147     0.039237\n",
      "mûre        0.020094    0.193546     0.039079\n",
      "grain       0.020083    0.193448     0.039060\n",
      "origan      0.020049    0.193154     0.039000\n",
      "thon        0.019982    0.192566     0.038881\n",
      "agneau      0.023131    0.220014     0.038743\n",
      "safran      0.019903    0.191878     0.038743\n",
      "gingembre   0.019824    0.191190     0.038604\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(full_metrics.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
